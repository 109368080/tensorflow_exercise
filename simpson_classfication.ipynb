{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpson_img = pd.read_csv('../simpsons_dataset/simpson_img_list.csv')\n",
    "print(simpson_img.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../simpsons_dataset/' + simpson_img.img.iloc[0], 0)\n",
    "print(type(img))\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpson_img = simpson_img[simpson_img.img.str.contains('simpson')]  #只取名字含有simpson的類別\n",
    "\n",
    "simpson_y = pd.get_dummies(simpson_img['classname'], '').as_matrix()#將label做 one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = simpson_img, simpson_y\n",
    "\n",
    "img = cv2.resize(img, (50, 50))\n",
    "img = img.flatten()\n",
    "print('input_data shape: training {training_shape}'.format(\n",
    "            training_shape=(len(x_train), img.shape[0])))\n",
    "print('y_true shape: training {training_shape}'.format(\n",
    "            training_shape=y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def simpson_train_batch_generator(x, y, bs, shape):\n",
    "    x_train = np.array([]).reshape((0, shape))\n",
    "    y_train = np.array([]).reshape((0, y.shape[1]))\n",
    "    while True:\n",
    "        new_ind = shuffle(range(len(x)))\n",
    "        x = x.take(new_ind)\n",
    "        y = np.take(y, new_ind, axis = 0)\n",
    "        for i in range(len(x)):\n",
    "            dir_img = '../simpsons_dataset/' + x.img.iloc[i]\n",
    "            img = cv2.imread(dir_img, 0)\n",
    "            img = cv2.resize(img, (50,50))\n",
    "            x_train = np.row_stack([x_train, img.flatten()])\n",
    "            y_train = np.row_stack([y_train, y[i]])\n",
    "            if x_train.shape[0] == bs:\n",
    "                x_batch = x_train.copy()\n",
    "                x_batch /= 255.\n",
    "                y_batch = y_train.copy()\n",
    "                x_train = np.array([]).reshape((0 ,shape))\n",
    "                y_train = np.array([]).reshape((0 ,y.shape[1]))        \n",
    "                yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立placeholder\n",
    "input_data = tf.placeholder(dtype = tf.float32, shape = [None, img.shape[0]], name = 'input_data')\n",
    "y_true = tf.placeholder(dtype = tf.float32, shape = [None,  y_train.shape[1]], name = 'y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立dense層神經網路\n",
    "x1 = tf.layers.dense(input_data, 512, activation = tf.nn.sigmoid, name='hidden1')\n",
    "x2 = tf.layers.dense(x1, 256, activation = tf.nn.sigmoid, name = 'hidden2')\n",
    "x3 = tf.layers.dense(x2, 128, activation = tf.nn.sigmoid, name = 'hidden3')\n",
    "x4 = tf.layers.dense(x3, 64, activation = tf.nn.sigmoid, name = 'hidden4')\n",
    "x5 = tf.layers.dense(x4, 32, activation = tf.nn.sigmoid, name = 'hidden5')\n",
    "out = tf.layers.dense(x5, y_train.shape[1], name = 'output')\n",
    "y_pred = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義 Loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義優化器\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "\n",
    "update = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#檢查Variables\n",
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #用來顯示進度條的套件\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epoch = 30 #epoch\n",
    "bs = 32 #batch size\n",
    "update_per_epoch = 100 #一個epoch要跑幾個batch\n",
    "\n",
    "tr_loss = list() #存training過程中的loss值\n",
    "tr_acc = list() #存training過程中的準確率\n",
    "train_gen = simpson_train_batch_generator(x_train, y_train, bs, img.shape[0])\n",
    "\n",
    "for i in range(epoch):\n",
    "    training_loss = 0\n",
    "    training_acc = 0\n",
    "    bar = tqdm(range(update_per_epoch))\n",
    "    \n",
    "    for j in tqdm(range(update_per_epoch)):\n",
    "        x_batch, y_batch = next(train_gen)\n",
    "        tr_pred, training_loss_batch, _ = sess.run([y_pred, loss, update], feed_dict = {\n",
    "            input_data : x_batch,\n",
    "            y_true : y_batch\n",
    "        })\n",
    "        training_loss += training_loss_batch\n",
    "        training_acc_batch = accuracy_score(np.argmax(y_batch, axis=1), np.argmax(tr_pred, axis=1))\n",
    "        training_acc += training_acc_batch\n",
    "        \n",
    "        if j % 5 == 0:\n",
    "            bar.set_description('loss: %.4g' % training_loss_batch) #進度條\n",
    "            \n",
    "    training_loss /= update_per_epoch\n",
    "    training_acc /= update_per_epoch\n",
    "    \n",
    "    tr_loss.append(training_loss)\n",
    "    tr_acc.append(training_acc)\n",
    "    \n",
    "    print('epoch {epochs}: training loss {training_loss}'.format(\n",
    "            epochs = (i+1), \n",
    "            training_loss = training_loss))#每個epoch結束後顯示目前的的training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(tr_loss)), tr_loss, label='training')\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(tr_acc)), tr_acc, label='training')\n",
    "plt.title('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
